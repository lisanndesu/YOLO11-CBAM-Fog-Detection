# ============ fog_gate.py ============
import torch
import torch.nn as nn
import torch.nn.functional as F

# ============ fog_gate.py ============
# class FogGate(nn.Module):
#     def __init__(self, *_, reduction=16):   # ä¸å†æ¥æ”¶ channels
#         super().__init__()
#         # å»¶è¿Ÿå»ºç«‹å·ç§¯ï¼Œç­‰ç¬¬ä¸€æ¬¡ forward å†çŸ¥é“é€šé“æ•°
#         self.reduction = reduction
#         self.t_est = None                    # å ä½
#
#     def forward(self, x):
#         if self.t_est is None:               # ç¬¬ä¸€æ¬¡å»ºç«‹
#             c = x.size(1)
#             self.t_est = nn.Sequential(
#                 nn.AdaptiveAvgPool2d(1),
#                 nn.Conv2d(c, c // self.reduction, 1, bias=False),
#                 nn.ReLU(inplace=True),
#                 nn.Conv2d(c // self.reduction, 1, 1, bias=False)
#             ).to(x.device)
#         # åç»­æ­£å¸¸è®¡ç®—
#         t = self.t_est(x)
#         gate = torch.sigmoid(1 - t)
#         dark = x.min(dim=1, keepdim=True)[0]
#         out = dark * gate.expand_as(dark) * x
#         return x + out


# ============= ffa_light_gate.py =============
# class FogGate(nn.Module):
#     """
#     è½»é‡ FFA-style é—¨æ§ï¼š
#     1. é€šé“åˆ†ç»„å·ç§¯ä¼°è®¡é€å°„ç‡ï¼ˆå¹³æ»‘ï¼‰
#     2. æ®‹å·®å¢å¼ºæµ“é›¾åŒºåŸŸ
#     æ¥å£ä»ä¿æŒ __init__(*_, reduction=16) å…¼å®¹ yaml
#     """
#     def __init__(self, *_, reduction=16, groups=4):
#         super().__init__()
#         self.reduction = reduction
#         self.groups    = groups
#         self.t_est = None   # å»¶è¿Ÿå»ºç«‹
#
#     def forward(self, x):
#         if self.t_est is None:
#             c = x.size(1)
#             self.t_est = nn.Sequential(
#                 nn.AdaptiveAvgPool2d(1),
#                 # åˆ†ç»„ 1Ã—1 å·ç§¯ï¼šå¹³æ»‘ä¸”å‚æ•°å°‘
#                 nn.Conv2d(c, c//self.reduction, 1, groups=self.groups, bias=False),
#                 nn.ReLU(inplace=True),
#                 nn.Conv2d(c//self.reduction, 1, 1, bias=False)
#             ).to(x.device)
#
#         t   = self.t_est(x)            # [B,1,1,1]
#         gate = torch.sigmoid(1 - t)    # æµ“é›¾â†’å¤§é—¨æ§å€¼
#         dark = x.min(dim=1, keepdim=True)[0]
#         out  = dark * gate.expand_as(dark) * x
#         return x + out                 # æ®‹å·®è¿æ¥


# æ”¹è¿›æ–¹æ¡ˆï¼šã€Œç‰¹å¾çº§ä¸ç¡®å®šæ€§é—¨æ§ã€â€”â€”ä¸ç”¨é˜ˆå€¼ï¼Œè®©ç½‘ç»œè‡ªå·±å­¦
class FogGate(nn.Module):
    def __init__(self, *_, reduction=16):
        super().__init__()
        self.reduction = reduction      # ğŸ”´ å­˜èµ·æ¥
        self.t_est = None
        self.uncertainty = nn.Parameter(torch.tensor(0.5))

    def forward(self, x):
        if self.t_est is None:
            c = x.size(1)
            self.t_est = nn.Sequential(
                nn.AdaptiveAvgPool2d(1),
                nn.Conv2d(c, c // self.reduction, 1, bias=False),  # ç”¨ self.reduction
                nn.ReLU(inplace=True),
                nn.Conv2d(c // self.reduction, 1, 1, bias=False)
            ).to(x.device)

        w = torch.sigmoid(self.uncertainty)
        t = self.t_est(x)
        gate = torch.sigmoid(1 - t)
        dark = x.min(dim=1, keepdim=True)[0]
        out = dark * gate.expand_as(dark) * x
        return x + w * out